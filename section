#!/usr/bin/env ruby

require 'net/http'
require 'fileutils'
require 'tempfile'
require 'open-uri'
require 'rubygems/package'
require 'json'
require 'stringio'

STDOUT.sync = true

OpenSSL::SSL::SSLContext::DEFAULT_PARAMS[:ssl_version] = :TLSv1_2

TAR_LONGLINK = '././@LongLink'.freeze

SECTION_CLI_PATH = File.expand_path(File.dirname(__FILE__))
VAGRANT_PATH = File.join(SECTION_CLI_PATH, 'vagrant')
APPS_PATH = File.join(SECTION_CLI_PATH, 'apps')
INSTANCE_TOKEN_FILE = File.join(VAGRANT_PATH, 'hiera', 'instance_token')
INSTANCE_CONFIG_FILE = File.join(VAGRANT_PATH, 'hiera', 'config.json')
REPOSITORY_PATH_FILE = File.join(VAGRANT_PATH, 'hiera', 'repository_path')
APP_ID_FILE = File.join(VAGRANT_PATH, 'hiera', 'app_id')
ENV_ID_FILE = File.join(VAGRANT_PATH, 'hiera', 'env_id')
REPOSITORIES_DIR = File.join(VAGRANT_PATH, 'hiera', 'repos')
APERTURE_DOMAIN = ENV['APERTURE_DOMAIN'] || 'aperture.section.io'
APERTURE_SCHEME = ENV['APERTURE_SCHEME'] || 'https'
SECTION_IO_THUMBPRINT_SHA1 = 'dcf837d21228e3e4c9a4293aabbf1d14e4d6c01a'.freeze
SECTION_IO_THUMBPRINT_SHA1_LEGACY = '0dea50cf4cfd5d9c031e265106214065f0d3f7b3'
                                    .freeze
SECTION_DATA_DIR = File.expand_path('~/.section')
FileUtils.mkdir_p SECTION_DATA_DIR
SECTION_CLI_UPDATE_FILE = File.join(SECTION_DATA_DIR, 'last-update')
SECTION_TARBALL_URL = ENV['SECTION_TARBALL_URL'] || 'http://s3-ap-southeast-2.amazonaws.com/section/section-delivery/localdev.tar.gz'
$git_executable_path = nil
$git_version = nil

require 'logger'
require 'english'

# DEBUG < INFO < WARN < ERROR < FATAL < UNKNOWN/ANY

# Logger
class SectionLogger
  attr_reader :file_name

  def initialize
    @console_logger = Logger.new(STDERR)
    @console_logger.level = ENV['SECTION_DEBUG'] == 'true' ? Logger::DEBUG : Logger::INFO
    @console_logger.formatter = proc do |severity, _, _, msg|
      severity == 'ANY' ? "#{msg}\n" : "#{severity}: #{msg}\n"
    end

    @file_name = File.join(SECTION_CLI_PATH, 'section.debug.log')
    @file = File.open(@file_name, 'w+') # File::APPEND | File::CREAT |File::WRONLY
    @file_logger = Logger.new(@file)
    @file_logger.level = Logger::DEBUG
    @file_logger.formatter = proc do |severity, datetime, _, msg|
      severity = 'USER' if severity == 'ANY'
      "#{datetime} [#{severity}]: #{msg}\n"
    end
  end

  def debug(progname = nil, &block)
    @console_logger.debug progname, &block
    @file_logger.debug progname, &block
  end

  def info(progname = nil, &block)
    @console_logger.info progname, &block
    @file_logger.info progname, &block
  end

  def warn(progname = nil, &block)
    @console_logger.warn progname, &block
    @file_logger.warn progname, &block
  end

  def error(progname = nil, &block)
    @console_logger.error progname, &block
    @file_logger.error progname, &block
  end

  def fatal(progname = nil, &block)
    @console_logger.fatal progname, &block
    @file_logger.fatal progname, &block
  end

  def unknown(progname = nil, &block)
    @console_logger.unknown progname, &block
    @file_logger.unknown progname, &block
  end

  # Default user-level messages
  def user(progname = nil, &block)
    unknown progname, &block
  end
end

def log_exit(err_msg, err_location)
  unless err_msg.nil?
    @logger.debug "Exiting message: #{err_msg.inspect}"
    @logger.debug "Backtrace: #{err_location}"
  end
  @logger.debug 'Exiting'
end

at_exit { log_exit $ERROR_INFO, $ERROR_POSITION }

@logger = SectionLogger.new
def http_get_response(uri, additional_headers = {}, &block)
  uri = URI.parse(uri)
  @logger.debug "uri to fetch is '#{uri}'"

  http = Net::HTTP.new(uri.host, uri.port)
  request = Net::HTTP::Get.new uri.request_uri

  # If a request to aperture via https verify the certificate and send the basic auth header
  if uri.scheme == 'https' && uri.host == APERTURE_DOMAIN
    http.use_ssl = true
    http.verify_mode = OpenSSL::SSL::VERIFY_PEER
    http.verify_callback = lambda do |_, ssl_context|
      thumbprint = OpenSSL::Digest::SHA1.new(ssl_context.chain[0].to_der).to_s
      @logger.debug "TLS certificate thumbprint is '#{thumbprint}'"
      return true if thumbprint == SECTION_IO_THUMBPRINT_SHA1
      return true if thumbprint == SECTION_IO_THUMBPRINT_SHA1_LEGACY
      return false
    end

    request.basic_auth 'section.cli', IO.read(INSTANCE_TOKEN_FILE)
  end

  request['User-Agent'] = user_agent
  additional_headers.each do |key, value|
    request[key] = value
  end

  http.request request, nil, &block
end

def get_cache_expiry_date(response)
  max_age = /max-age=(\d+)/i.match response['Cache-Control'] { |match| match[1].to_i } unless response['Cache-Control'].nil?

  return Time.now + max_age if max_age
end

def http_download_file(uri, destination_path, destination_file_type = 't')
  response_status = nil
  additional_headers = {}

  # Send the If-None-Match header if there is an .etag file for the file
  etag_file_path = "#{destination_path}.etag"
  cached_etag = IO.read(etag_file_path) if File.exist?(etag_file_path)
  additional_headers['If-None-Match'] = cached_etag unless cached_etag.nil? || cached_etag.empty? || !File.exist?(destination_path)

  # Check the cache file expiry date against now
  expiry_file_path = "#{destination_path}.expiry"
  cached_expiry = Time.parse(IO.read(expiry_file_path)) if File.exist?(expiry_file_path)
  unless cached_expiry.nil? || Time.now > cached_expiry || !File.exist?(destination_path)
    @logger.debug "Not downloading due to existing cache not expired, cache expires #{cached_expiry}"
    return response_status
  end

  http_get_response uri, additional_headers do |response|
    response_status = response.code
    if response.is_a?(Net::HTTPSuccess)
      File.open(etag_file_path, 'w+') { |f| f.write(response['ETag']) } unless response['ETag'].nil?
      cached_expiry = get_cache_expiry_date(response)
      File.open(expiry_file_path, 'w+') { |f| f.write(cached_expiry) } unless cached_expiry.nil?

      @logger.debug "Writing download to #{destination_path}"
      file_mode = "w#{destination_file_type}"
      File.open(destination_path, file_mode) do |cache_file|
        response.read_body do |segment|
          cache_file.write(segment)
        end
      end
    end
  end

  response_status
end

def http_download_string(uri)
  response = http_get_response uri
  response.body
end
def section_append(proxy_template_name, proxy_name)
  # Get the available proxytemplate list
  proxy_templates = load_proxy_templates

  # If no proxy_template_name provided show error displaying the available template names
  if proxy_template_name.nil? || proxy_template_name.empty?
    display_section_append_usage
    display_section_append_available_templates(proxy_templates)
    abort
  end

  # If the proxy_template_name doesn't match the available list show error displaying the available template names
  proxy_template = proxy_templates.find { |t| t['name'] == proxy_template_name }
  if proxy_template.nil?
    @logger.user "\n*** Invalid proxy_template_name '#{proxy_template_name}' ***\n\n"
    display_section_append_available_templates(proxy_templates)
    abort
  end

  # If no proxy_name default to the proxy image name
  if proxy_name.nil? || proxy_name.empty?
    proxy_name = proxy_template_name.split(':')[0]
    proxy_name = proxy_name.gsub(/[^a-z0-9]/i, '')
    @logger.debug "Defaulting the new proxy name to #{proxy_name} since one was not provided"
  end

  # If proxy_name is invalid show error
  display_append_error "\n*** invalid proxy_name '#{proxy_name}', can only contain letters or numbers ***\n" unless valid_proxy_name?(proxy_name)

  @logger.debug('Load up the section.config.json and append the new proxy')
  config = load_and_validate_section_config_json

  # If proxyname has already been used show error
  # TODO: Check that the name doesn't match reserved folder names like custom_errors
  if config['proxychain'].any? { |p| p['name'] == proxy_name }
    display_append_error "\n*** invalid proxy_name '#{proxy_name}', a proxy with that name already exists. Please specify a different name. ***\n"
  end

  new_proxy = { name: proxy_name, image: proxy_template['image'] }
  config['proxychain'].push(new_proxy)
  update_section_config_json(config)

  @logger.debug("Downloading inital proxy state files for #{proxy_template_name}")
  initial_state_api_uri = "#{APERTURE_SCHEME}://#{APERTURE_DOMAIN}/api/v1/proxytemplate/initialstate?proxyTemplateName=#{URI.escape(proxy_template_name)}"
  initial_state_file_string = http_download_string initial_state_api_uri
  initial_state_file = StringIO.new initial_state_file_string

  repo_dir = IO.read(REPOSITORY_PATH_FILE)
  initial_state_destination = File.join(repo_dir, proxy_name)
  @logger.debug("Extracting initial state into #{initial_state_destination}")
  extract_tar_gzip(initial_state_file, initial_state_destination)

  @logger.user "Proxy #{proxy_name} has been added to your repository, now reloading your local instance to reflect these changes.\n"
  @logger.user ' ** WARNING ** Currently, automatically pushing a new proxy into your Production hosted environment is not a'
  @logger.user '               supported action. Pushing this change into your Production environment can cause your proxy'
  @logger.user '               stack to behave unexpectedly. Once you have tested your new proxy and you would like to deploy'
  @logger.user '               it, please submit a support request via https://support.section.io/ to get it pushed live.'
  section_reload
end

def display_section_append_usage
  @logger.user "\nUsage: \n\tsection append <proxy_template_name>[ <proxy_name>]\n\n"
end

def display_append_error(message)
  @logger.user message
  display_section_append_usage
  abort
end

def display_section_append_available_templates(proxy_templates)
  @logger.user "-- Available proxy_template_names --\n"
  proxy_templates.each do |t|
    @logger.user " * '#{t['name']}' - #{t['label']}, #{t['description']}"
  end
end
def extract_tar_gzip(source, destination)
  # If the source is a string, treat it as a path to a local file
  gzip_reader = source.instance_of?(String) ? Zlib::GzipReader.open(source) : Zlib::GzipReader.new(source)

  Gem::Package::TarReader.new(gzip_reader) do |tar|
    dest = nil
    tar.each do |entry|
      if entry.full_name == TAR_LONGLINK
        dest = File.join destination, entry.read.strip
        next
      end
      dest ||= File.join destination, entry.full_name
      if entry.directory?
        FileUtils.rm_rf dest unless File.directory? dest
        FileUtils.mkdir_p dest, mode: entry.header.mode, verbose: false
      elsif entry.file?
        FileUtils.mkdir_p File.dirname(dest), verbose: false
        FileUtils.rm_rf dest unless File.file? dest
        File.open dest, 'wb' do |f|
          f.print entry.read
        end
        FileUtils.chmod entry.header.mode, dest, verbose: false
      elsif entry.header.typeflag == '2' # Symlink!
        File.symlink entry.header.linkname, dest
      end
      dest = nil
    end
  end
end
SECTION_PROXYTEMPLATE_FILE = File.join(SECTION_DATA_DIR, 'proxy_templates.json')
LEGACY_IMAGE_NAMES = ['varnish', 'varnish-4.0.3', 'varnish3', 'varnish3magento', 'varnish305vmods', 'modsecurity'].freeze

def download_proxy_templates_from_api
  # Catch http fetch errors because the local cache can be used if it's available
  http_download_file "#{APERTURE_SCHEME}://#{APERTURE_DOMAIN}/api/v1/proxytemplate", SECTION_PROXYTEMPLATE_FILE
rescue StandardError => err
  @logger.warn("Unable to load proxy templates from API: #{err.message}")
end

def load_proxy_templates
  @logger.debug 'Loading proxy template list'

  download_proxy_templates_from_api

  @logger.debug "Checking proxy template list cache file '#{SECTION_PROXYTEMPLATE_FILE}'"
  templates_str = IO.read(SECTION_PROXYTEMPLATE_FILE) if File.exist?(SECTION_PROXYTEMPLATE_FILE)

  if templates_str.nil? || templates_str.empty?
    @logger.error('Unable to load proxy template list, no local cache available')
    abort
  end

  # JSON parse API respone
  begin
    JSON.parse(templates_str)
  rescue JSON::ParserError => err
    error_detail = err.message[0, 80]
    error_detail += '...' if err.message.length > 80
    @logger.error "Could not fetch proxytemplate list JSON file:\n#{error_detail}"
    abort
  end
end

def valid_proxy_chain?(config, json_file)
  invalid_proxy = config['proxychain'].find { |p| p['name'] !~ /^[0-9a-z]+$/i }
  if invalid_proxy
    @logger.error "Proxy name '#{invalid_proxy['name']}' is invalid in #{json_file}, proxy names can only contain alphanumeric characters"
    return false
  end

  proxy_templates = load_proxy_templates
  public_image_names = proxy_templates.map { |t| t['image'] }.uniq
  valid_image_names = public_image_names + LEGACY_IMAGE_NAMES
  invalid_proxy = config['proxychain'].find { |p| !valid_image_names.include?(p['image']) }
  if invalid_proxy
    @logger.error "Image '#{invalid_proxy['image']}' for proxy name '#{invalid_proxy['name']}' is not a valid image name in #{json_file}"
    @logger.user "       Valid images names are: #{public_image_names.join(', ')}"
    return false
  end

  true
end

def display_command_options
  puts "\n Options:\n"
  puts "   * up <token> - Bring up a new section virtual machine for the specified instance token\n"
  puts "   * init <token> - Make the application for the specified instance token the current application./\n"
  puts "   * append <proxyTemplateName> <proxyName> - Add a new proxy to your stack./\n"
  puts "   * status - Show the git status for your current local application repository\n"
  puts "   * reload - Reload local proxy stack with your changes\n"
  puts "   * pull - Pull down any updates commited to your git repository\n"
  puts "   * push <commit message> - Commit and push local changes to your git repository\n"
  puts "   * promote - Merge the current branch into Production and push result to your git repository\n"
  puts "   * --help - Display this help content\n"

  puts "\n Documentation can be found at https://www.section.io/docs/cli/\n"
  puts "\n Submit any support questions to https://support.section.io or support@section.io"
end

def user_agent
  _, section_commit = cmd_execute(SECTION_CLI_PATH, 'git rev-parse --short HEAD')
  # NOTE section_commit will be wrong if we `git pull SECTION_CLI_PATH` before we run this code
  result = "section.cli/#{section_commit}"

  result += " #{RUBY_ENGINE}/#{RUBY_VERSION} (#{RUBY_PLATFORM})"

  exit_status, vagrant_version = cmd_execute(SECTION_CLI_PATH, 'vagrant --version')
  if exit_status == 0
    vagrant_version.sub!(/^vagrant\s*/i, '')
    result += " vagrant/#{vagrant_version}"
  end

  result + " git/#{$git_version}"

  # TODO: SSH version
end

def get_instance_config(token)
  config_str = http_download_string("#{APERTURE_SCHEME}://#{APERTURE_DOMAIN}/instance/getconfig?token=#{token}")
  File.open(INSTANCE_CONFIG_FILE, 'w+') { |f| f.write(config_str) }
  JSON.parse(config_str)
end

def local_instance_config
  if !File.exist?(INSTANCE_CONFIG_FILE)
    @logger.user 'No local config file, loading from aperture'
    if File.exist?(INSTANCE_TOKEN_FILE)
      token = IO.read(INSTANCE_TOKEN_FILE)
      @logger.user "Running with existing token '#{token}'"
      return get_instance_config(token)
    else
      @logger.user 'Unable to read the local config file, please run section up with your instance token'
    end
  else
    config_str = IO.read(INSTANCE_CONFIG_FILE)
    return JSON.parse(config_str)
  end
end

# Cross-platform way of finding an executable in the $PATH.
#  From: http://stackoverflow.com/a/5471032/20819
#   which('ruby') #=> /usr/bin/ruby
def which(cmd)
  exts = ENV['PATHEXT'] ? ENV['PATHEXT'].split(';') : ['']
  ENV['PATH'].split(File::PATH_SEPARATOR).each do |path|
    exts.each { |ext|
      exe = File.join(path, "#{cmd}#{ext}")
      return exe if File.executable?(exe) && !File.directory?(exe)
    }
  end
  return nil
end

def download_latest_vagrant_if_needed
  @logger.user 'Checking for latest vagrant files'

  uri = URI.parse(SECTION_TARBALL_URL)
  file_name = File.basename(uri.path)
  unzip_destination = SECTION_CLI_PATH
  cache_file_path = File.join(SECTION_DATA_DIR, file_name)

  response_status = http_download_file SECTION_TARBALL_URL, cache_file_path, 'b'

  if response_status == '200'
    @logger.debug("Extracting #{cache_file_path} to #{unzip_destination}")
    extract_tar_gzip(cache_file_path, unzip_destination)
  else
    @logger.debug "Not extracting #{cache_file_path} since http request returned a #{response_status || 'nil'} response code"
  end
end

def update_app_repo_dir(config)
  index = 0
  while index < config['accounts'][0]['applications'].length

    application_config = config['accounts'][0]['applications'][index]
    environment_config = application_config['environments'][0]
    application_name = application_config['name']
    @logger.user "Processing application: #{application_name}"
    file_friendly_app_name = application_name.gsub(/[^a-z0-9_\.\-]+/, '_').downcase
    app_directory = File.join(APPS_PATH, file_friendly_app_name)
    section_config_json_file = File.join(app_directory, 'section.config.json')

    if index == 0
      # For the first application, collect the state files as this is the app that has section up run and will have command like push and pull run against it
      File.open(REPOSITORY_PATH_FILE, 'w+') { |f| f.write(app_directory) } # Write the path to the current repository
      File.open(APP_ID_FILE, 'w+') { |f| f.write(application_config['application_id']) } # Write the current app id
      File.open(ENV_ID_FILE, 'w+') { |f| f.write(environment_config['environment_id']) } # Write the current env id
    end

    if Dir.exist?(app_directory)
      if File.exist?(section_config_json_file)
        # Leave it in intact
        @logger.user 'Repository exists and will not be altered'
      else
        abort "Unknown state, cannot continue. Missing file #{section_config_json_file}"
      end
    else
      @logger.user 'Creating repository'
      FileUtils.mkdir_p app_directory
      git_cmd = "git clone \"#{application_config['repository']}\" #{file_friendly_app_name}"
      clone_succeeded = cmd_execute_interactive(APPS_PATH, git_cmd)
      unless clone_succeeded
        Dir.rmdir app_directory
        abort "Could not clone #{application_config['repository']}"
      end
    end

    hook_target = File.join(app_directory, '.git/hooks/pre-commit')
    unless File.exist?(hook_target)
      File.link(File.join(SECTION_CLI_PATH, 'git-hooks-pre-commit'), hook_target)
      File.chmod(0755, hook_target)
    end

    File.open("#{REPOSITORY_PATH_FILE}.app.#{application_config['application_id']}", 'w+') { |f| f.write(app_directory) } # Write the path to the repository here

    index += 1
  end
end

def load_and_validate_section_config_json
  repo_dir = IO.read(REPOSITORY_PATH_FILE)
  json_file = File.join(repo_dir, 'section.config.json')
  begin
    config = JSON.parse(IO.read(json_file))
  rescue JSON::ParserError => err
    error_detail = err.message[0, 80]
    error_detail += '...' if err.message.length > 80
    abort "Error Could not parse JSON file '#{json_file}':\n#{error_detail}"
  end

  abort unless valid_proxy_chain?(config, json_file)

  config
end

def update_section_config_json(config)
  repo_dir = IO.read(REPOSITORY_PATH_FILE)
  json_file = File.join(repo_dir, 'section.config.json')
  @logger.debug("Updating #{json_file}")
  File.open(json_file, 'w+') { |f| f.write(JSON.pretty_generate(config, indent: '    ')) }
end

def get_repo_dirname(app_id, env_id)
  app_id = IO.read(APP_ID_FILE) unless app_id

  env_id = IO.read(ENV_ID_FILE) unless env_id

  "app#{app_id}-env#{env_id}"
end

def copy_app_repo_to_hiera(config)
  # sync apps\friendlyname to C:\squixa\section.cli\vagrant\hiera\repos\<N>

  config['accounts'][0]['applications'].each do |application_config|
    source_dir = IO.read("#{REPOSITORY_PATH_FILE}.app.#{application_config['application_id']}")
    dest_dir = File.join(REPOSITORIES_DIR, get_repo_dirname(application_config['application_id'], application_config['environments'][0]['environment_id']))
    @logger.debug "Copying #{source_dir} to #{dest_dir}"
    FileUtils.mkdir_p dest_dir
    FileUtils.cp_r(File.join(source_dir, '.'), dest_dir, remove_destination: true)
  end
end

def copy_app_repo_to_volume_source(config)
  container_volume_repo_path = File.join('/opt/section.delivery/hiera/repos/')

  ssh_cmd = []

  config['accounts'][0]['applications'].each do |application_config|
    vagrant_mapped_repo_path = File.join('/vagrant/hiera/repos/', get_repo_dirname(application_config['application_id'], application_config['environments'][0]['environment_id']))

    ssh_cmd.push("sudo rsync -a --delete --delete-during --delete-excluded --exclude .git #{vagrant_mapped_repo_path} #{container_volume_repo_path}")

    ssh_cmd.push("sudo /vagrant/remove-containers-if-proxystack-changed.sh #{application_config['application_id']} #{application_config['environments'][0]['environment_id']}")
  end

  vagrant_execute('ssh', ['-c', ssh_cmd.join(' && ')])
end

def section_init
  # update section cli if not attempted for more than an hour, or if forced by environment variable
  _, before_section_commit = cmd_execute(SECTION_CLI_PATH, 'git rev-parse --short HEAD')
  @logger.debug "CLI commit hash is #{before_section_commit} before update"
  @logger.debug "SECTION_CLI_UPDATE_FILE is '#{SECTION_CLI_UPDATE_FILE}'"
  update_section_cli_now = !File.exist?(SECTION_CLI_UPDATE_FILE) || File.mtime(SECTION_CLI_UPDATE_FILE) < (Time.now - 60 * 60)
  @logger.debug "File-derived value for update_section_cli_now is #{update_section_cli_now}"
  update_section_cli_now = (ENV['SECTION_CLI_UPDATE'] == 'true') if ENV['SECTION_CLI_UPDATE'] # force either on or off
  @logger.debug "Environment-overridden value for update_section_cli_now is #{update_section_cli_now}"
  if update_section_cli_now
    exit_status, = cmd_execute(SECTION_CLI_PATH, 'git pull')
    @logger.warn 'Warning: could not check for update to latest version of section.cli' unless exit_status == 0
    FileUtils.touch SECTION_CLI_UPDATE_FILE
    _, after_section_commit = cmd_execute(SECTION_CLI_PATH, 'git rev-parse --short HEAD')
    @logger.debug "CLI commit hash is #{after_section_commit} after update"
    if before_section_commit != after_section_commit
      @logger.user 'The section.io CLI has been updated, please re-run your command'
      exit 1
    end
  end

  # TODO: Allow a command line arg to force a reload
  # if not File.directory?(VAGRANT_PATH)
  download_latest_vagrant_if_needed
  # end

  if !ARGV[1].nil?
    FileUtils.mkdir_p File.join(VAGRANT_PATH, 'hiera') # , :verbose => false
    token = ARGV[1]

    File.open(INSTANCE_TOKEN_FILE, 'w+') { |f| f.write(ARGV[1]) }
  elsif File.exist?(INSTANCE_TOKEN_FILE)
    token = IO.read(INSTANCE_TOKEN_FILE)
    @logger.user "Running with existing token '#{token}'"
  else
    @logger.error "Please provide your instance token as a parameter\nie. \n\tsection up <token>"
    abort "You can obtain the instance token by logging in to aperture.section.io and selecting the instance you are trying to launch\n"
  end

  config = get_instance_config(token)
  update_app_repo_dir(config)
  load_and_validate_section_config_json
  copy_app_repo_to_hiera(config)
end

require 'open3'

def cmd_execute(path, cmd)
  Open3.popen3(cmd, chdir: path) do |_, stdout, stderr, wait_thr|
    @logger.debug "Running [#{path}] #{cmd}"

    exit_status = wait_thr.value # Process::Status object returned.
    stdout_result = stdout.read.chomp
    stderr_result = stderr.read.chomp

    @logger.debug "exit_status: #{exit_status}"
    @logger.debug "stdout: #{stdout_result}"
    @logger.debug "stderr: #{stderr_result}"
    return exit_status, stdout_result, stderr_result
  end
end

def cmd_execute_interactive(path, cmd)
  @logger.debug "Running [#{path}] #{cmd}"
  system(cmd, chdir: path)
end

require 'open3'

# Error for vagrant_execute
class VagrantExecuteError < StandardError
  attr_reader :stdout
  attr_reader :stderr
  attr_reader :exit_status

  def initialize(msg, stdout, stderr, exit_status)
    @stdout = stdout
    @stderr = stderr
    @exit_status = exit_status
    super(msg)
  end
end

def vagrant_execute(subcommand, args = [])
  @logger.debug "Running Vagrant #{subcommand} with args: #{args}"
  @logger.debug "Overriding PATH for Vagrant: #{@vagrant_env_path}"
  all_args = ['vagrant', subcommand].concat(args)

  stdin, stdout, stderr, wait_thr = Open3.popen3({ 'PATH' => @vagrant_env_path }, *all_args, chdir: VAGRANT_PATH)

  pid = wait_thr[:pid] # pid of the started process
  @logger.debug "pid: #{pid}"
  stdout_lines = []
  stderr_lines = []

  stdout.each do |line|
    @logger.debug "stdout: #{line.rstrip}"
    stdout_lines.push(line)
  end

  stderr.each do |line|
    @logger.debug "stderr: #{line.rstrip}"
    stderr_lines.push(line)
  end

  # wait_thr.value waits the termination of the process
  process_status = wait_thr.value # Process::Status object returned
  exit_status = process_status.exitstatus

  stdout_result = stdout.read.chomp
  stderr_result = stderr.read.chomp

  unless stderr_result.empty?
    @logger.debug "stdout: #{stdout_result.rstrip}"
    stdout_lines.push(stdout_result)
  end

  unless stderr_result.empty?
    @logger.debug "stderr: #{stderr_result.rstrip}"
    stderr_lines.push(stderr_result)
  end

  # stdin, stdout and stderr must be closed explicitly in this form
  stdin.close
  stdout.close
  stderr.close

  @logger.debug "exit_status: #{exit_status}"

  # Any non-zero exit is unexpected
  raise VagrantExecuteError.new('Unexpected non-zero return value', stdout_lines, stderr_lines, exit_status) unless exit_status == 0

  exit_status
end

def branch_name
  repo_path = IO.read(REPOSITORY_PATH_FILE)

  exit_status, stdout, = cmd_execute(repo_path, 'git rev-parse --abbrev-ref HEAD')
  abort 'Couldn\'t check for clean git working copy' unless exit_status == 0
  abort 'Couldn\'t determine current HEAD' if stdout.empty?
  stdout
end

def section_promote
  destination_branch = 'Production'

  repo_path = IO.read(REPOSITORY_PATH_FILE)

  # Get current branch name
  original_branch = branch_name

  # Set source branch name to current branch name
  source_branch = original_branch

  # Check that we're not already on the Production branch
  abort "Already on the #{destination_branch} branch, just use `section push`" unless source_branch != destination_branch

  # Check that there are no local changes
  exit_status, stdout, = cmd_execute(repo_path, 'git status --porcelain')
  abort 'Could\'t check for clean git working copy' unless exit_status == 0
  abort '"section push" or discard changes before continuing.' if stdout.empty?

  # Push current branch
  cmd_execute_interactive(repo_path, 'git push origin') || abort('Failed to push current branch')

  # Checkout destination branch
  cmd_execute(repo_path, "git checkout #{destination_branch}") || abort("Couldn't checkout #{destination_branch}")

  # Pull destination branch
  cmd_execute_interactive(repo_path, 'git pull') || abort("Couldn't update #{destination_branch}")

  # Merge source branch into destination branch
  cmd_execute(repo_path, "git merge --no-ff -m \"#{source_branch} merged to #{destination_branch}\" #{source_branch}") || exit

  # Push destination branch
  cmd_execute_interactive(repo_path, 'git push') || exit

  # Checkout original branch
  cmd_execute(repo_path, "git checkout #{original_branch}") || exit
end # section_promote

def section_status
  git_path = IO.read(REPOSITORY_PATH_FILE)
  git_cmd = 'git status'

  @logger.user("[#{git_path}] #{git_cmd}")
  _, stdout, = system(git_cmd, chdir: git_path)
  @logger.user(stdout)
end

def section_reload
  load_and_validate_section_config_json
  vagrant_execute('ssh', ['-c', 'sudo /vagrant/remove-appid-only-artifacts.sh;'])
  config = local_instance_config
  copy_app_repo_to_hiera(config)
  copy_app_repo_to_volume_source(config)

  app_id = IO.read(APP_ID_FILE)

  # TODO: remove this step, local reload should not contact the Internet
  vagrant_execute('ssh', ['-c', "sudo /vagrant/hiera/generate_hiera.sh && sudo /vagrant/run-puppet.sh && sudo /vagrant/update_containers.sh #{app_id};"])

  # TODO: test the exit codes of the above commands before declaring success
  @logger.user 'section.io proxy stack updated with the latest changes'
end

def ensure_git_valid
  $git_executable_path = which('git')

  unless $git_executable_path
    @logger.user 'git must be installed and on the PATH.'
    exit 1
  end

  exit_status, $git_version, std_err = cmd_execute(SECTION_CLI_PATH, 'git --version')
  if exit_status == 0
    $git_version.sub!(/^git\s+version\s*/i, '')
    $git_version_parts = $git_version.split('.') if $git_version

    if !$git_version_parts || ($git_version_parts[0].to_i < 2)
      @logger.user "git version 2.0 or greater is required, currently installed version is #{$git_version}"
      exit 1
    end
  else
    @logger.user "Unable to obtain git version, error when running `git --version`: #{std_err}"
    exit exit_status
  end
end

def ensure_ssh_on_vagrant_path
  @vagrant_env_path = ENV['PATH'].dup

  return if which('ssh')

  # check for ssh in git directory for Windows
  try_ssh_directory_paths = [
    File.dirname($git_executable_path),
    File.join(File.dirname($git_executable_path), '..', 'bin'),
    File.join(File.dirname($git_executable_path), '..', 'usr', 'bin')
  ]

  ssh_path = try_ssh_directory_paths.find { |try_ssh_directory_path| File.executable?(File.join(try_ssh_directory_path, 'ssh.exe')) }

  return @vagrant_env_path << File::PATH_SEPARATOR + ssh_path if ssh_path

  @logger.user 'SSH must be installed and on the PATH.' # TODO: recommend an OS-specific source for SSH
  exit 1
end

# TODO: report all missing dependencies before exiting for a better user experience

# TODO: test for VirtualBox installation

def init
  @logger.debug "SECTION_CLI_PATH is '#{SECTION_CLI_PATH}'"
  @logger.debug "Command line arguments: #{$ARGV}"
  @logger.debug "Ruby version: #{RUBY_VERSION}-p#{RUBY_PATCHLEVEL}"

  unless which('vagrant')
    @logger.user 'Vagrant must be installed and on the PATH. Vagrant can be downloaded at https://www.vagrantup.com/'
    exit 1
  end

  ensure_git_valid
  ensure_ssh_on_vagrant_path
end

def main
  case ARGV[0]
  when 'init'
    section_init

  when 'up'
    section_init

    @logger.user 'Starting virtual machine if required'
    vagrant_execute('up')
    @logger.user 'Configuring virtual machine'
    vagrant_execute('ssh', ['-c', 'sudo /vagrant/remove-appid-only-artifacts.sh && sudo /vagrant/bootstrap.sh;'])

  when 'reload'
    section_reload

  when 'pull'
    git_path = IO.read(REPOSITORY_PATH_FILE)
    git_cmd = 'git pull'
    @logger.user("[#{git_path}] #{git_cmd}")
    system(git_cmd, chdir: git_path)

  when 'status'
    # NOTE: This will be deprecated by working directory context project
    section_status

  when 'push'
    if ARGV[1].nil? || ARGV[1].empty?
      abort "*** Missing commit message ***\n\nUsage: \n\tsection push \"Commit message\""
    end

    commit_message = ARGV[1]
    git_path = IO.read(REPOSITORY_PATH_FILE)

    git_cmd = 'git add .'
    @logger.user("[#{git_path}] #{git_cmd}")
    system(git_cmd, chdir: git_path)

    git_cmd = "git commit -m \"#{commit_message}\""
    @logger.user("[#{git_path}] #{git_cmd}")
    system(git_cmd, chdir: git_path)

    git_cmd = 'git push'
    @logger.user("[#{git_path}] #{git_cmd}")
    system(git_cmd, chdir: git_path)

  when 'promote'
    section_promote

  when 'append'
    section_append(ARGV[1], ARGV[2])

  when '--help'
    display_command_options

  when nil
    @logger.error 'Missing command'
    display_command_options
    exit 1

  else
    @logger.error "Invalid command '#{ARGV[0]}'"
    display_command_options
    exit 1
  end
end

begin
  init
  main
rescue StandardError => e

  if e.is_a?(VagrantExecuteError) && e.stderr.any? { |l| l.include?('VM must be running to open SSH connection.') }
    @logger.user "It looks like the virtual machine isn't running. Have you run 'section up' first?"
  end

  @logger.fatal "An unhandled exception occurred. Details available in #{@logger.file_name}"
  @logger.debug "Unhandled exception: #{e.inspect}"
  @logger.debug "Backtrace: #{e.backtrace.inspect}"
end
